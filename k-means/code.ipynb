{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7cfb32cd",
   "metadata": {},
   "source": [
    "# k-nearest neighbor\n",
    "\n",
    "The k-Nearest Neighbors algorithm or KNN for short is a very simple technique.\n",
    "\n",
    "The entire training dataset is stored. When a prediction is required, the k-most similar records to a new record from the training dataset are then located. From these neighbors, a summarized prediction is made.\n",
    "\n",
    "Similarity between records can be measured many different ways. A problem or data-specific method can be used. Generally, with tabular data, a good starting point is the Euclidean distance.\n",
    "\n",
    "Once the neighbors are discovered, the summary prediction can be made by returning the most common outcome or taking the average. As such, KNN can be used for classification or regression problems.\n",
    "\n",
    "There is no model to speak of other than holding the entire training dataset. Because no work is done until a prediction is required, KNN is often referred to as a lazy learning method.\n",
    "\n",
    "k-Nearest Neighbors (in 3 easy steps)\n",
    "First we will develop each piece of the algorithm in this section, then we will tie all of the elements together into a working implementation applied to a real dataset in the next section.\n",
    "\n",
    " ### k-Nearest Neighbors tutorial is broken down into 3 parts:\n",
    "\n",
    "## Step 1: Calculate Euclidean Distance.\n",
    "\n",
    "## Step 2: Get Nearest Neighbors.\n",
    "\n",
    "## Step 3: Make Predictions.\n",
    "\n",
    "These steps will teach you the fundamentals of implementing and applying the k-Nearest Neighbors algorithm for classification and regression predictive modeling problems.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f07a7f14",
   "metadata": {},
   "source": [
    "## Step 1: Calculate Euclidean Distance\n",
    "The first step is to calculate the distance between two rows in a dataset.\n",
    "\n",
    "Rows of data are mostly made up of numbers and an easy way to calculate the distance between two rows or vectors of numbers is to draw a straight line. This makes sense in 2D or 3D and scales nicely to higher dimensions.\n",
    "\n",
    "We can calculate the straight line distance between two vectors using the Euclidean distance measure. It is calculated as the square root of the sum of the squared differences between the two vectors.\n",
    "\n",
    "Euclidean Distance = sqrt(sum i to N (x1_i â€“ x2_i)^2)\n",
    "Where x1 is the first row of data, x2 is the second row of data and i is the index to a specific column as we sum across all columns.\n",
    "\n",
    "With Euclidean distance, the smaller the value, the more similar two records will be. A value of 0 means that there is no difference between two records."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f8eddfa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fe94e6ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidean_distance(row1, row2):\n",
    "    distance=0.0\n",
    "    for i in range(len(row1)):\n",
    "        distance+=(row1[i]-row2[i])**2\n",
    "    return np.sqrt(distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d66574ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = [[2.7810836,2.550537003,0],\n",
    "[1.465489372,2.362125076,0],\n",
    "[3.396561688,4.400293529,0],\n",
    "[1.38807019,1.850220317,0],\n",
    "[3.06407232,3.005305973,0],\n",
    "[7.627531214,2.759262235,1],\n",
    "[5.332441248,2.088626775,1],\n",
    "[6.922596716,1.77106367,1],\n",
    "[8.675418651,-0.242068655,1],\n",
    "[7.673756466,3.508563011,1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6ea27c01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "1.3290173915275787\n",
      "1.9494646655653247\n",
      "1.5591439385540549\n",
      "0.5356280721938492\n",
      "4.952940611164215\n",
      "2.7789902674782985\n",
      "4.3312480380207\n",
      "6.59862349695304\n",
      "5.084885603993178\n"
     ]
    }
   ],
   "source": [
    "row0=dataset[0]\n",
    "for row in dataset:\n",
    "    distance=euclidean_distance(row0,row)\n",
    "    print(distance)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1e237c0",
   "metadata": {},
   "source": [
    "## Step 2: Get Nearest Neighbors\n",
    "Neighbors for a new piece of data in the dataset are the k closest instances, as defined by our distance measure.\n",
    "\n",
    "To locate the neighbors for a new piece of data within a dataset we must first calculate the distance between each record in the dataset to the new piece of data. We can do this using our distance function prepared above.\n",
    "\n",
    "Once distances are calculated, we must sort all of the records in the training dataset by their distance to the new data. We can then select the top k to return as the most similar neighbors.\n",
    "\n",
    "We can do this by keeping track of the distance for each record in the dataset as a tuple, sort the list of tuples by the distance (in descending order) and then retrieve the neighbors.\n",
    "\n",
    "Below is a function named get_neighbors() that implements this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "dd483b95",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_neighbors(train, test_row, num_neighbors):\n",
    "    distances=list()\n",
    "    for train_row in train:\n",
    "        dist=euclidean_distance(test_row,train_row)\n",
    "        distances.append((train_row,dist))\n",
    "    distances.sort(key=lambda tup: tup[1])\n",
    "    neighbors=list()\n",
    "    for i in range(num_neighbors):\n",
    "        neighbors.append(distances[i][0])\n",
    "    return neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "83bb7bef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.7810836, 2.550537003, 0]\n",
      "[3.06407232, 3.005305973, 0]\n",
      "[1.465489372, 2.362125076, 0]\n"
     ]
    }
   ],
   "source": [
    "neighbors = get_neighbors(dataset, dataset[0], 3)\n",
    "for neighbor in neighbors:\n",
    "    print(neighbor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c715fcba",
   "metadata": {},
   "source": [
    "# Step 3: Make Predictions\n",
    "The most similar neighbors collected from the training dataset can be used to make predictions.\n",
    "\n",
    "In the case of classification, we can return the most represented class among the neighbors.\n",
    "\n",
    "We can achieve this by performing the max() function on the list of output values from the neighbors. Given a list of class values observed in the neighbors, the max() function takes a set of unique class values and calls the count on the list of class values for each class value in the set.\n",
    "\n",
    "Below is the function named predict_classification() that implements this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "16b68a22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_classification(train, test_row, num_neighbors):\n",
    "    neighbors = get_neighbors(train, test_row, num_neighbors)\n",
    "    output_values = [row[-1] for row in neighbors]\n",
    "    prediction = max(set(output_values), key=output_values.count)\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "6ad5583d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected 0, Got 0.\n"
     ]
    }
   ],
   "source": [
    "prediction = predict_classification(dataset, dataset[0], 3)\n",
    "print('Expected %d, Got %d.' % (dataset[0][-1], prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91cc218b",
   "metadata": {},
   "source": [
    "# iris flower"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "111b3333",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Make Predictions with k-nearest neighbors on the Iris Flowers Dataset\n",
    "from csv import reader\n",
    "from math import sqrt\n",
    "# Load a CSV file\n",
    "def load_csv(filename):\n",
    "\tdataset = list()\n",
    "\twith open(filename, 'r') as file:\n",
    "\t\tcsv_reader = reader(file)\n",
    "\t\tfor row in csv_reader:\n",
    "\t\t\tif not row:\n",
    "\t\t\t\tcontinue\n",
    "\t\t\tdataset.append(row)\n",
    "\treturn dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "3a9daac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert string column to float\n",
    "def str_column_to_float(dataset, column):\n",
    "\tfor row in dataset:\n",
    "\t\trow[column] = float(row[column].strip())\n",
    "# Convert string column to integer\n",
    "def str_column_to_int(dataset, column):\n",
    "\tclass_values = [row[column] for row in dataset]\n",
    "\tunique = set(class_values)\n",
    "\tlookup = dict()\n",
    "\tfor i, value in enumerate(unique):\n",
    "\t\tlookup[value] = i\n",
    "\t\tprint('[%s] => %d' % (value, i))\n",
    "\tfor row in dataset:\n",
    "\t\trow[column] = lookup[row[column]]\n",
    "\treturn lookup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "87af1ff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the min and max values for each column\n",
    "def dataset_minmax(dataset):\n",
    "\tminmax = list()\n",
    "\tfor i in range(len(dataset[0])):\n",
    "\t\tcol_values = [row[i] for row in dataset]\n",
    "\t\tvalue_min = min(col_values)\n",
    "\t\tvalue_max = max(col_values)\n",
    "\t\tminmax.append([value_min, value_max])\n",
    "\treturn minmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "df8f4ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rescale dataset columns to the range 0-1\n",
    "# def normalize_dataset(dataset, minmax):\n",
    "# \tfor row in dataset:\n",
    "# \t\tfor i in range(len(row)):\n",
    "# \t\t\trow[i] = (row[i] - minmax[i][0]) / (minmax[i][1] - minmax[i][0])\n",
    "\n",
    "# Calculate the Euclidean distance between two vectors\n",
    "def euclidean_distance(row1, row2):\n",
    "\tdistance = 0.0\n",
    "\tfor i in range(len(row1)-1):\n",
    "\t\tdistance += (row1[i] - row2[i])**2\n",
    "\treturn sqrt(distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "d13aef42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Locate the most similar neighbors\n",
    "def get_neighbors(train, test_row, num_neighbors):\n",
    "\tdistances = list()\n",
    "\tfor train_row in train:\n",
    "\t\tdist = euclidean_distance(test_row, train_row)\n",
    "\t\tdistances.append((train_row, dist))\n",
    "\tdistances.sort(key=lambda tup: tup[1])\n",
    "\tneighbors = list()\n",
    "\tfor i in range(num_neighbors):\n",
    "\t\tneighbors.append(distances[i][0])\n",
    "\treturn neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "e0e225d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Make a prediction with neighbors\n",
    "def predict_classification(train, test_row, num_neighbors):\n",
    "\tneighbors = get_neighbors(train, test_row, num_neighbors)\n",
    "\toutput_values = [row[-1] for row in neighbors]\n",
    "\tprediction = max(set(output_values), key=output_values.count)\n",
    "\treturn prediction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "88fd946c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iris-virginica] => 0\n",
      "[Iris-versicolor] => 1\n",
      "[Iris-setosa] => 2\n"
     ]
    }
   ],
   "source": [
    "# # Make a prediction with KNN on Iris Dataset\n",
    "filename = './iris.csv'\n",
    "dataset = load_csv(filename)\n",
    "for i in range(len(dataset[0])-1):\n",
    "\tstr_column_to_float(dataset, i)\n",
    "# # convert class column to integers\n",
    "str_column_to_int(dataset, len(dataset[0])-1)\n",
    "# # # define model parameter\n",
    "num_neighbors = 5\n",
    "# # # define a new record\n",
    "row = [5.7,2.9,4.2,1.3]\n",
    "# # # predict the label\n",
    "# label = predict_classification(dataset, row, num_neighbors)\n",
    "# print('Data=%s, Predicted: %s' % (row, label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "988065f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "932c6823",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da146ad9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d1147c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d00fb6d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11159e56",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "99da6b4a",
   "metadata": {},
   "source": [
    "# k-means "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "18056b77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from scipy.stats import mode\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fb99bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# K Nearest Neighbors Classification\n",
    "\n",
    "class K_Nearest_Neighbors_Classifier() :\n",
    "\t\n",
    "\tdef __init__( self, K ) :\n",
    "\t\t\n",
    "\t\tself.K = K\n",
    "\t\t\n",
    "\t# Function to store training set\n",
    "\t\t\n",
    "\tdef fit( self, X_train, Y_train ) :\n",
    "\t\t\n",
    "\t\tself.X_train = X_train\n",
    "\t\t\n",
    "\t\tself.Y_train = Y_train\n",
    "\t\t\n",
    "\t\t# no_of_training_examples, no_of_features\n",
    "\t\t\n",
    "\t\tself.m, self.n = X_train.shape\n",
    "\t\n",
    "\t# Function for prediction\n",
    "\t\t\n",
    "\tdef predict( self, X_test ) :\n",
    "\t\t\n",
    "\t\tself.X_test = X_test\n",
    "\t\t\n",
    "\t\t# no_of_test_examples, no_of_features\n",
    "\t\t\n",
    "\t\tself.m_test, self.n = X_test.shape\n",
    "\t\t\n",
    "\t\t# initialize Y_predict\n",
    "\t\t\n",
    "\t\tY_predict = np.zeros( self.m_test )\n",
    "\t\t\n",
    "\t\tfor i in range( self.m_test ) :\n",
    "\t\t\t\n",
    "\t\t\tx = self.X_test[i]\n",
    "\t\t\t\n",
    "\t\t\t# find the K nearest neighbors from current test example\n",
    "\t\t\t\n",
    "\t\t\tneighbors = np.zeros( self.K )\n",
    "\t\t\t\n",
    "\t\t\tneighbors = self.find_neighbors( x )\n",
    "\t\t\t\n",
    "\t\t\t# most frequent class in K neighbors\n",
    "\t\t\t\n",
    "\t\t\tY_predict[i] = mode( neighbors )[0][0]\t\n",
    "\t\t\t\n",
    "\t\treturn Y_predict\n",
    "\t\n",
    "\t# Function to find the K nearest neighbors to current test example\n",
    "\t\t\t\n",
    "\tdef find_neighbors( self, x ) :\n",
    "\t\t\n",
    "\t\t# calculate all the euclidean distances between current\n",
    "\t\t# test example x and training set X_train\n",
    "\t\t\n",
    "\t\teuclidean_distances = np.zeros( self.m )\n",
    "\t\t\n",
    "\t\tfor i in range( self.m ) :\n",
    "\t\t\t\n",
    "\t\t\td = self.euclidean( x, self.X_train[i] )\n",
    "\t\t\t\n",
    "\t\t\teuclidean_distances[i] = d\n",
    "\t\t\n",
    "\t\t# sort Y_train according to euclidean_distance_array and\n",
    "\t\t# store into Y_train_sorted\n",
    "\t\t\n",
    "\t\tinds = euclidean_distances.argsort()\n",
    "\t\t\n",
    "\t\tY_train_sorted = self.Y_train[inds]\n",
    "\t\t\n",
    "\t\treturn Y_train_sorted[:self.K]\n",
    "\t\n",
    "\t# Function to calculate euclidean distance\n",
    "\t\t\t\n",
    "\tdef euclidean( self, x, x_train ) :\n",
    "\t\t\n",
    "\t\treturn np.sqrt( np.sum( np.square( x - x_train ) ) )\n",
    "\n",
    "# Driver code\n",
    "\n",
    "def main() :\n",
    "\t\n",
    "\t# Importing dataset\n",
    "\t\n",
    "\tdf = pd.read_csv( \"diabetes.csv\" )\n",
    "\n",
    "\tX = df.iloc[:,:-1].values\n",
    "\n",
    "\tY = df.iloc[:,-1:].values\n",
    "\t\n",
    "\t# Splitting dataset into train and test set\n",
    "\n",
    "\tX_train, X_test, Y_train, Y_test = train_test_split(\n",
    "\tX, Y, test_size = 1/3, random_state = 0 )\n",
    "\t\n",
    "\t# Model training\n",
    "\t\n",
    "\tmodel = K_Nearest_Neighbors_Classifier( K = 3 )\n",
    "\t\n",
    "\tmodel.fit( X_train, Y_train )\n",
    "\t\n",
    "\tmodel1 = KNeighborsClassifier( n_neighbors = 3 )\n",
    "\t\n",
    "\tmodel1.fit( X_train, Y_train )\n",
    "\t\n",
    "\t# Prediction on test set\n",
    "\n",
    "\tY_pred = model.predict( X_test )\n",
    "\t\n",
    "\tY_pred1 = model1.predict( X_test )\n",
    "\t\n",
    "\t# measure performance\n",
    "\t\n",
    "\tcorrectly_classified = 0\n",
    "\t\n",
    "\tcorrectly_classified1 = 0\n",
    "\t\n",
    "\t# counter\n",
    "\t\n",
    "\tcount = 0\n",
    "\t\n",
    "\tfor count in range( np.size( Y_pred ) ) :\n",
    "\t\t\n",
    "\t\tif Y_test[count] == Y_pred[count] :\n",
    "\t\t\t\n",
    "\t\t\tcorrectly_classified = correctly_classified + 1\n",
    "\t\t\n",
    "\t\tif Y_test[count] == Y_pred1[count] :\n",
    "\t\t\t\n",
    "\t\t\tcorrectly_classified1 = correctly_classified1 + 1\n",
    "\t\t\t\n",
    "\t\tcount = count + 1\n",
    "\t\t\n",
    "\tprint( \"Accuracy on test set by our model\t : \", (\n",
    "\tcorrectly_classified / count ) * 100 )\n",
    "\tprint( \"Accuracy on test set by sklearn model : \", (\n",
    "\tcorrectly_classified1 / count ) * 100 )\n",
    "\t\n",
    "\t\n",
    "if __name__ == \"__main__\" :\n",
    "\t\n",
    "\tmain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "c117afc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"./diabetes.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "7566406a",
   "metadata": {},
   "outputs": [],
   "source": [
    "x= df.iloc[:,:-1].values\n",
    "y=df.iloc[:,-1:].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "43d449b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(x, y, test_size = 1/3, random_state = 0 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "ad582db0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(x_train, y_train):\n",
    "    x_train=x_train\n",
    "    y_train=y_train\n",
    "    m,n=x_train.shape\n",
    "    return m,n\n",
    "def predict(X_test ) :\n",
    "    X_test = X_test\n",
    "    # no_of_test_examples, no_of_features\n",
    "    m_test,n = X_test.shape    \n",
    "    y_predict=np.zeros(m_test)\n",
    "    for i in range(m_test):\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "edeba16f",
   "metadata": {},
   "outputs": [],
   "source": [
    "m,n=fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "6a62d3ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0.]\n",
      "[0. 0. 0.]\n",
      "[0. 0. 0.]\n",
      "[0. 0. 0.]\n",
      "[0. 0. 0.]\n",
      "[0. 0. 0.]\n",
      "[0. 0. 0.]\n",
      "[0. 0. 0.]\n",
      "[0. 0. 0.]\n",
      "[0. 0. 0.]\n",
      "[0. 0. 0.]\n",
      "[0. 0. 0.]\n",
      "[0. 0. 0.]\n",
      "[0. 0. 0.]\n",
      "[0. 0. 0.]\n",
      "[0. 0. 0.]\n",
      "[0. 0. 0.]\n",
      "[0. 0. 0.]\n",
      "[0. 0. 0.]\n",
      "[0. 0. 0.]\n",
      "[0. 0. 0.]\n",
      "[0. 0. 0.]\n",
      "[0. 0. 0.]\n",
      "[0. 0. 0.]\n",
      "[0. 0. 0.]\n",
      "[0. 0. 0.]\n",
      "[0. 0. 0.]\n",
      "[0. 0. 0.]\n",
      "[0. 0. 0.]\n",
      "[0. 0. 0.]\n",
      "[0. 0. 0.]\n",
      "[0. 0. 0.]\n",
      "[0. 0. 0.]\n",
      "[0. 0. 0.]\n",
      "[0. 0. 0.]\n",
      "[0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "# m_test=X_test.shape[0]\n",
    "for i in range(m_test):\n",
    "    new_=X_test[i]\n",
    "    neighbors = np.zeros(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce3ff2e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce17d40c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33839317",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71455451",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d985388c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89dc76d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a84a32e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b38b89a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e1045b1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
